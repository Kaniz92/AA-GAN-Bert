{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kaniz92/AA-GAN-Bert/blob/main/notebooks/AA_GAN_Bert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GhPTWnyregAp"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/Kaniz92/AA-GAN-Bert.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YMDzi0y-e_8-"
      },
      "outputs": [],
      "source": [
        "cd AA-GAN-Bert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zLJFdnRrRUjX"
      },
      "outputs": [],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Nb1aBCOYb8j"
      },
      "outputs": [],
      "source": [
        "!huggingface-cli login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hYkfQC3KmLUa"
      },
      "outputs": [],
      "source": [
        "cd /content/AA-GAN-Bert"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2SrIXDKCrHY"
      },
      "source": [
        "# Train and Save Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WCJ094oISke-"
      },
      "outputs": [],
      "source": [
        "!PYTHONPATH=./:$PYTHONPATH python run_modal.py \\\n",
        "    --wandb_project_name='experiment_1_authors_20_trial_1'\\\n",
        "    --training_strategy='best_modal_on_wandb'\\\n",
        "    --sample_size=20 \\\n",
        "    --sampling_strategy='n_samples_sequential'\\\n",
        "    --dataset='experiment_1'\\\n",
        "    --dataset_dir='authors_20/trial_1'\\\n",
        "    --num_train_epochs=10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CAJqk450OCzf"
      },
      "source": [
        "# testing models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TfIK-XmiQBkB"
      },
      "source": [
        "### load main model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "tNCGRlYMQ8g0"
      },
      "outputs": [],
      "source": [
        "!rm -rf /content/AA-GAN-Bert/artifacts_main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZL2ZWpqPOOAG"
      },
      "outputs": [],
      "source": [
        "import wandb\n",
        "run = wandb.init()\n",
        "\n",
        "alias = 'authorship-attribution/experiment_1_authors_20_trial_1/gan_bert_model:v0'\n",
        "artifact = run.use_artifact(alias, type='model')\n",
        "artifact_dir = artifact.download()\n",
        "\n",
        "\n",
        "run.join()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWSFV3naQE33"
      },
      "source": [
        "### transfer learning and save model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mZfcnY_QPFcf"
      },
      "outputs": [],
      "source": [
        "# RENAME ARTIFACTS DIR BEFORE RUNNING THIS\n",
        "!PYTHONPATH=./:$PYTHONPATH python run_modal.py \\\n",
        "    --wandb_project_name='experiment_1_authors_18_trial_1'\\\n",
        "    --training_strategy='best_modal_on_wandb'\\\n",
        "    --model_name='artifacts/gan_bert_model:v0' \\\n",
        "    --sample_size=20 \\\n",
        "    --sampling_strategy='n_samples_sequential'\\\n",
        "    --dataset='experiment_1'\\\n",
        "    --dataset_dir='authors_18/trial_1'\\\n",
        "    --num_train_epochs=5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mWlQAIsdGoiy"
      },
      "outputs": [],
      "source": [
        "# RENAME ARTIFACTS DIR BEFORE RUNNING THIS\n",
        "!PYTHONPATH=./:$PYTHONPATH python run_modal.py \\\n",
        "    --wandb_project_name='experiment_1_authors_18_trial_2'\\\n",
        "    --training_strategy='best_modal_on_wandb'\\\n",
        "    --model_name='artifacts/gan_bert_model:v0' \\\n",
        "    --sample_size=20 \\\n",
        "    --sampling_strategy='n_samples_sequential'\\\n",
        "    --dataset='experiment_1'\\\n",
        "    --dataset_dir='authors_18/trial_2'\\\n",
        "    --num_train_epochs=5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aQAeyQo-GrdV"
      },
      "outputs": [],
      "source": [
        "# RENAME ARTIFACTS DIR BEFORE RUNNING THIS\n",
        "!PYTHONPATH=./:$PYTHONPATH python run_modal.py \\\n",
        "    --wandb_project_name='experiment_1_authors_18_trial_3'\\\n",
        "    --training_strategy='best_modal_on_wandb'\\\n",
        "    --model_name='artifacts/gan_bert_model:v0' \\\n",
        "    --sample_size=20 \\\n",
        "    --sampling_strategy='n_samples_sequential'\\\n",
        "    --dataset='experiment_1'\\\n",
        "    --dataset_dir='authors_18/trial_3'\\\n",
        "    --num_train_epochs=5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mDoqkWjaGuet"
      },
      "outputs": [],
      "source": [
        "# RENAME ARTIFACTS DIR BEFORE RUNNING THIS\n",
        "!PYTHONPATH=./:$PYTHONPATH python run_modal.py \\\n",
        "    --wandb_project_name='experiment_1_authors_18_trial_4'\\\n",
        "    --training_strategy='best_modal_on_wandb'\\\n",
        "    --model_name='artifacts/gan_bert_model:v0' \\\n",
        "    --sample_size=20 \\\n",
        "    --sampling_strategy='n_samples_sequential'\\\n",
        "    --dataset='experiment_1'\\\n",
        "    --dataset_dir='authors_18/trial_4'\\\n",
        "    --num_train_epochs=5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6SNYrlp5GwyM"
      },
      "outputs": [],
      "source": [
        "# RENAME ARTIFACTS DIR BEFORE RUNNING THIS\n",
        "!PYTHONPATH=./:$PYTHONPATH python run_modal.py \\\n",
        "    --wandb_project_name='experiment_1_authors_18_trial_5'\\\n",
        "    --training_strategy='best_modal_on_wandb'\\\n",
        "    --model_name='artifacts/gan_bert_model:v0' \\\n",
        "    --sample_size=20 \\\n",
        "    --sampling_strategy='n_samples_sequential'\\\n",
        "    --dataset='experiment_1'\\\n",
        "    --dataset_dir='authors_18/trial_5'\\\n",
        "    --num_train_epochs=5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gi5k1kpWzb1b"
      },
      "source": [
        "### Standalone training and save modal\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FBTizDEAzj7W"
      },
      "outputs": [],
      "source": [
        "# RENAME ARTIFACTS DIR BEFORE RUNNING THIS\n",
        "!PYTHONPATH=./:$PYTHONPATH python run_modal.py \\\n",
        "    --wandb_project_name='experiment_1_authors_16_trial_1'\\\n",
        "    --training_strategy='best_modal_on_wandb'\\\n",
        "    --sample_size=20 \\\n",
        "    --sampling_strategy='n_samples_sequential'\\\n",
        "    --dataset='experiment_1'\\\n",
        "    --dataset_dir='authors_16/trial_1'\\\n",
        "    --num_train_epochs=5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lycZ3K1SC_BS"
      },
      "outputs": [],
      "source": [
        "# RENAME ARTIFACTS DIR BEFORE RUNNING THIS\n",
        "!PYTHONPATH=./:$PYTHONPATH python run_modal.py \\\n",
        "    --wandb_project_name='experiment_1_authors_16_trial_2'\\\n",
        "    --training_strategy='best_modal_on_wandb'\\\n",
        "    --sample_size=20 \\\n",
        "    --sampling_strategy='n_samples_sequential'\\\n",
        "    --dataset='experiment_1'\\\n",
        "    --dataset_dir='authors_16/trial_2'\\\n",
        "    --num_train_epochs=5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ycPQllHdDGCb"
      },
      "outputs": [],
      "source": [
        "# RENAME ARTIFACTS DIR BEFORE RUNNING THIS\n",
        "!PYTHONPATH=./:$PYTHONPATH python run_modal.py \\\n",
        "    --wandb_project_name='experiment_1_authors_16_trial_3'\\\n",
        "    --training_strategy='best_modal_on_wandb'\\\n",
        "    --sample_size=20 \\\n",
        "    --sampling_strategy='n_samples_sequential'\\\n",
        "    --dataset='experiment_1'\\\n",
        "    --dataset_dir='authors_16/trial_3'\\\n",
        "    --num_train_epochs=5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k35fghXEDJPN"
      },
      "outputs": [],
      "source": [
        "# RENAME ARTIFACTS DIR BEFORE RUNNING THIS\n",
        "!PYTHONPATH=./:$PYTHONPATH python run_modal.py \\\n",
        "    --wandb_project_name='experiment_1_authors_18_trial_4'\\\n",
        "    --training_strategy='best_modal_on_wandb'\\\n",
        "    --sample_size=20 \\\n",
        "    --sampling_strategy='n_samples_sequential'\\\n",
        "    --dataset='experiment_1'\\\n",
        "    --dataset_dir='authors_18/trial_4'\\\n",
        "    --num_train_epochs=5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WwNkF_NGDMJw"
      },
      "outputs": [],
      "source": [
        "# RENAME ARTIFACTS DIR BEFORE RUNNING THIS\n",
        "!PYTHONPATH=./:$PYTHONPATH python run_modal.py \\\n",
        "    --wandb_project_name='experiment_1_authors_18_trial_5'\\\n",
        "    --training_strategy='best_modal_on_wandb'\\\n",
        "    --sample_size=20 \\\n",
        "    --sampling_strategy='n_samples_sequential'\\\n",
        "    --dataset='experiment_1'\\\n",
        "    --dataset_dir='authors_18/trial_5'\\\n",
        "    --num_train_epochs=5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X-gd6mIiWC3N"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2773oIWU7Yv"
      },
      "source": [
        "### transfer learning training with sample size\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VEvWYRsJVQU3"
      },
      "outputs": [],
      "source": [
        "!rm -rf /content/AA-GAN-Bert/artifacts_main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6YkbkcN_VQU5"
      },
      "outputs": [],
      "source": [
        "import wandb\n",
        "run = wandb.init()\n",
        "\n",
        "alias = 'authorship-attribution/experiment_1_authors_20_trial_1/gan_bert_model:v0'\n",
        "artifact = run.use_artifact(alias, type='model')\n",
        "artifact_dir = artifact.download()\n",
        "\n",
        "\n",
        "run.join()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n1FceHidU7Yx"
      },
      "outputs": [],
      "source": [
        "# RENAME ARTIFACTS DIR BEFORE RUNNING THIS\n",
        "!PYTHONPATH=./:$PYTHONPATH python run_modal.py \\\n",
        "    --wandb_project_name='experiment_1_authors_18_trial_1'\\\n",
        "    --training_strategy='best_modal_on_wandb'\\\n",
        "    --model_name='artifacts/gan_bert_model:v0' \\\n",
        "    --sample_size=30 \\\n",
        "    --sampling_strategy='n_samples_sequential'\\\n",
        "    --dataset='experiment_1'\\\n",
        "    --dataset_dir='authors_18/trial_1'\\\n",
        "    --num_train_epochs=5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IMaNs1ruU7Yy"
      },
      "outputs": [],
      "source": [
        "# RENAME ARTIFACTS DIR BEFORE RUNNING THIS\n",
        "!PYTHONPATH=./:$PYTHONPATH python run_modal.py \\\n",
        "    --wandb_project_name='experiment_1_authors_18_trial_2'\\\n",
        "    --training_strategy='best_modal_on_wandb'\\\n",
        "    --model_name='artifacts/gan_bert_model:v0' \\\n",
        "    --sample_size=30 \\\n",
        "    --sampling_strategy='n_samples_sequential'\\\n",
        "    --dataset='experiment_1'\\\n",
        "    --dataset_dir='authors_18/trial_2'\\\n",
        "    --num_train_epochs=5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "me3CR7C1U7Y0"
      },
      "outputs": [],
      "source": [
        "# RENAME ARTIFACTS DIR BEFORE RUNNING THIS\n",
        "!PYTHONPATH=./:$PYTHONPATH python run_modal.py \\\n",
        "    --wandb_project_name='experiment_1_authors_18_trial_3'\\\n",
        "    --training_strategy='best_modal_on_wandb'\\\n",
        "    --model_name='artifacts/gan_bert_model:v0' \\\n",
        "    --sample_size=30 \\\n",
        "    --sampling_strategy='n_samples_sequential'\\\n",
        "    --dataset='experiment_1'\\\n",
        "    --dataset_dir='authors_18/trial_3'\\\n",
        "    --num_train_epochs=5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nOlNRPDNU7Y1"
      },
      "outputs": [],
      "source": [
        "# RENAME ARTIFACTS DIR BEFORE RUNNING THIS\n",
        "!PYTHONPATH=./:$PYTHONPATH python run_modal.py \\\n",
        "    --wandb_project_name='experiment_1_authors_18_trial_4'\\\n",
        "    --training_strategy='best_modal_on_wandb'\\\n",
        "    --model_name='artifacts/gan_bert_model:v0' \\\n",
        "    --sample_size=30 \\\n",
        "    --sampling_strategy='n_samples_sequential'\\\n",
        "    --dataset='experiment_1'\\\n",
        "    --dataset_dir='authors_18/trial_4'\\\n",
        "    --num_train_epochs=5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VBLcDYXzU7Y1"
      },
      "outputs": [],
      "source": [
        "# RENAME ARTIFACTS DIR BEFORE RUNNING THIS\n",
        "!PYTHONPATH=./:$PYTHONPATH python run_modal.py \\\n",
        "    --wandb_project_name='experiment_1_authors_18_trial_5'\\\n",
        "    --training_strategy='best_modal_on_wandb'\\\n",
        "    --model_name='artifacts/gan_bert_model:v0' \\\n",
        "    --sample_size=30 \\\n",
        "    --sampling_strategy='n_samples_sequential'\\\n",
        "    --dataset='experiment_1'\\\n",
        "    --dataset_dir='authors_18/trial_5'\\\n",
        "    --num_train_epochs=5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GsREcMszOrE8"
      },
      "source": [
        "### Random sampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E-925n39fMf0"
      },
      "outputs": [],
      "source": [
        "!rm -rf /content/AA-GAN-Bert/artifacts_main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U_0o_W9vfMf1"
      },
      "outputs": [],
      "source": [
        "import wandb\n",
        "run = wandb.init()\n",
        "\n",
        "alias = 'authorship-attribution/experiment_1_authors_20_trial_1/gan_bert_model:v0'\n",
        "artifact = run.use_artifact(alias, type='model')\n",
        "artifact_dir = artifact.download()\n",
        "\n",
        "\n",
        "run.join()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3mTINApAPiMX",
        "outputId": "7b2757e6-7a8d-4442-9032-6c9759f54378"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/AA-GAN-Bert\n"
          ]
        }
      ],
      "source": [
        "cd /content/AA-GAN-Bert"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cpjFMD0JN79E"
      },
      "source": [
        "#### 50-samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eZ8ImR1LO1q8"
      },
      "outputs": [],
      "source": [
        "# RENAME ARTIFACTS DIR BEFORE RUNNING THIS\n",
        "# CASE 2\n",
        "# DONE 17/02/2023\n",
        "!PYTHONPATH=./:$PYTHONPATH python run_modal.py \\\n",
        "    --wandb_project_name='experiment_2_random_sampling_case_1'\\\n",
        "    --training_strategy='random_sampling_wandb'\\\n",
        "    --model_name='artifacts/gan_bert_model:v0' \\\n",
        "    --sample_size=20 \\\n",
        "    --sampling_strategy='n_samples_sequential'\\\n",
        "    --dataset='master-data'\\\n",
        "    --num_train_epochs=5 \\\n",
        "    --random_sampling_indexes_file='/content/AA-GAN-Bert/data/experiment_2/random_sampling_50_split_index.csv'\\\n",
        "    --case_id=2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hiw2lMDjZfTx"
      },
      "outputs": [],
      "source": [
        "# RENAME ARTIFACTS DIR BEFORE RUNNING THIS\n",
        "# CASE 4\n",
        "# DONE 17/02/2023\n",
        "!PYTHONPATH=./:$PYTHONPATH python run_modal.py \\\n",
        "    --wandb_project_name='experiment_2_random_sampling_case_4'\\\n",
        "    --training_strategy='random_sampling_wandb'\\\n",
        "    --model_name='artifacts/gan_bert_model:v0' \\\n",
        "    --sample_size=20 \\\n",
        "    --sampling_strategy='n_samples_sequential'\\\n",
        "    --dataset='master-data'\\\n",
        "    --num_train_epochs=5 \\\n",
        "    --random_sampling_indexes_file='/content/AA-GAN-Bert/data/experiment_2/random_sampling_50_split_index.csv'\\\n",
        "    --case_id=4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M1pBm6Y0ZoIN"
      },
      "outputs": [],
      "source": [
        "# RENAME ARTIFACTS DIR BEFORE RUNNING THIS\n",
        "# CASE 6\n",
        "# DONE 18/02/2023\n",
        "!PYTHONPATH=./:$PYTHONPATH python run_modal.py \\\n",
        "    --wandb_project_name='experiment_2_random_sampling_case_6'\\\n",
        "    --training_strategy='random_sampling_wandb'\\\n",
        "    --model_name='artifacts/gan_bert_model:v0' \\\n",
        "    --sample_size=20 \\\n",
        "    --sampling_strategy='n_samples_sequential'\\\n",
        "    --dataset='master-data'\\\n",
        "    --num_train_epochs=5 \\\n",
        "    --random_sampling_indexes_file='/content/AA-GAN-Bert/data/experiment_2/random_sampling_50_split_index.csv'\\\n",
        "    --case_id=6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rbzijtwcZrcT"
      },
      "outputs": [],
      "source": [
        "# RENAME ARTIFACTS DIR BEFORE RUNNING THIS\n",
        "# CASE 8\n",
        "# DONE 20/02/2023\n",
        "!PYTHONPATH=./:$PYTHONPATH python run_modal.py \\\n",
        "    --wandb_project_name='experiment_2_random_sampling_case_8'\\\n",
        "    --training_strategy='random_sampling_wandb'\\\n",
        "    --model_name='artifacts/gan_bert_model:v0' \\\n",
        "    --sample_size=20 \\\n",
        "    --sampling_strategy='n_samples_sequential'\\\n",
        "    --dataset='master-data'\\\n",
        "    --num_train_epochs=5 \\\n",
        "    --random_sampling_indexes_file='/content/AA-GAN-Bert/data/experiment_2/random_sampling_50_split_index.csv'\\\n",
        "    --case_id=8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iqfm1ksIZvP7"
      },
      "outputs": [],
      "source": [
        "# RENAME ARTIFACTS DIR BEFORE RUNNING THIS\n",
        "# CASE 10\n",
        "# DONE - 20/02/2023\n",
        "!PYTHONPATH=./:$PYTHONPATH python run_modal.py \\\n",
        "    --wandb_project_name='experiment_2_random_sampling_case_10'\\\n",
        "    --training_strategy='random_sampling_wandb'\\\n",
        "    --model_name='artifacts/gan_bert_model:v0' \\\n",
        "    --sample_size=20 \\\n",
        "    --sampling_strategy='n_samples_sequential'\\\n",
        "    --dataset='master-data'\\\n",
        "    --num_train_epochs=5 \\\n",
        "    --random_sampling_indexes_file='/content/AA-GAN-Bert/data/experiment_2/random_sampling_50_split_index.csv'\\\n",
        "    --case_id=10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qhBTUEuQZypk"
      },
      "outputs": [],
      "source": [
        "# RENAME ARTIFACTS DIR BEFORE RUNNING THIS\n",
        "# CASE 12\n",
        "# DONE - 21/2/2023\n",
        "!PYTHONPATH=./:$PYTHONPATH python run_modal.py \\\n",
        "    --wandb_project_name='experiment_2_random_sampling_case_12'\\\n",
        "    --training_strategy='random_sampling_wandb'\\\n",
        "    --model_name='artifacts/gan_bert_model:v0' \\\n",
        "    --sample_size=20 \\\n",
        "    --sampling_strategy='n_samples_sequential'\\\n",
        "    --dataset='master-data'\\\n",
        "    --num_train_epochs=5 \\\n",
        "    --random_sampling_indexes_file='/content/AA-GAN-Bert/data/experiment_2/random_sampling_50_split_index.csv'\\\n",
        "    --case_id=12"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qSnFpWIPe3SJ",
        "outputId": "0010dde7-3c7f-4298-ba97-19650977236d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/AA-GAN-Bert\n"
          ]
        }
      ],
      "source": [
        "cd AA-GAN-Bert/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "dKiC8yvBZ1cU"
      },
      "outputs": [],
      "source": [
        "# RENAME ARTIFACTS DIR BEFORE RUNNING THIS\n",
        "# CASE 14\n",
        "!PYTHONPATH=./:$PYTHONPATH python run_modal.py \\\n",
        "    --wandb_project_name='experiment_2_random_sampling_case_14'\\\n",
        "    --training_strategy='random_sampling_wandb'\\\n",
        "    --model_name='artifacts/gan_bert_model:v0' \\\n",
        "    --sample_size=20 \\\n",
        "    --sampling_strategy='n_samples_sequential'\\\n",
        "    --dataset='master-data'\\\n",
        "    --num_train_epochs=5 \\\n",
        "    --random_sampling_indexes_file='/content/AA-GAN-Bert/data/experiment_2/random_sampling_50_split_index.csv'\\\n",
        "    --case_id=14"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SS-LzZlzZ4FZ"
      },
      "outputs": [],
      "source": [
        "# RENAME ARTIFACTS DIR BEFORE RUNNING THIS\n",
        "# CASE 16\n",
        "!PYTHONPATH=./:$PYTHONPATH python run_modal.py \\\n",
        "    --wandb_project_name='experiment_2_random_sampling_case_16'\\\n",
        "    --training_strategy='random_sampling_wandb'\\\n",
        "    --model_name='artifacts/gan_bert_model:v0' \\\n",
        "    --sample_size=20 \\\n",
        "    --sampling_strategy='n_samples_sequential'\\\n",
        "    --dataset='master-data'\\\n",
        "    --num_train_epochs=5 \\\n",
        "    --random_sampling_indexes_file='/content/AA-GAN-Bert/data/experiment_2/random_sampling_50_split_index.csv'\\\n",
        "    --case_id=16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TlYuGillZ664"
      },
      "outputs": [],
      "source": [
        "# RENAME ARTIFACTS DIR BEFORE RUNNING THIS\n",
        "# CASE 18\n",
        "!PYTHONPATH=./:$PYTHONPATH python run_modal.py \\\n",
        "    --wandb_project_name='experiment_2_random_sampling_case_18'\\\n",
        "    --training_strategy='random_sampling_wandb'\\\n",
        "    --model_name='artifacts/gan_bert_model:v0' \\\n",
        "    --sample_size=20 \\\n",
        "    --sampling_strategy='n_samples_sequential'\\\n",
        "    --dataset='master-data'\\\n",
        "    --num_train_epochs=5 \\\n",
        "    --random_sampling_indexes_file='/content/AA-GAN-Bert/data/experiment_2/random_sampling_50_split_index.csv'\\\n",
        "    --case_id=18"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1p-1EIRuOE6L"
      },
      "source": [
        "#### 100-samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-tlDvHUJOOQm"
      },
      "outputs": [],
      "source": [
        "# RENAME ARTIFACTS DIR BEFORE RUNNING THIS\n",
        "# CASE 2\n",
        "!PYTHONPATH=./:$PYTHONPATH python run_modal.py \\\n",
        "    --wandb_project_name='experiment_3_random_sampling_case_2'\\\n",
        "    --training_strategy='random_sampling_wandb'\\\n",
        "    --model_name='artifacts/gan_bert_model:v0' \\\n",
        "    --sample_size=20 \\\n",
        "    --sampling_strategy='n_samples_sequential'\\\n",
        "    --dataset='master-data'\\\n",
        "    --num_train_epochs=5 \\\n",
        "    --random_sampling_indexes_file='/content/AA-GAN-Bert/data/experiment_2/random_sampling_100_split_index.csv'\\\n",
        "    --case_id=2 \\\n",
        "    --random_sample_size=100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vj2Xrq58PArd"
      },
      "outputs": [],
      "source": [
        "!PYTHONPATH=./:$PYTHONPATH python run_modal.py \\\n",
        "    --wandb_project_name='experiment_3_random_sampling_case_4'\\\n",
        "    --training_strategy='random_sampling_wandb'\\\n",
        "    --model_name='artifacts/gan_bert_model:v0' \\\n",
        "    --sample_size=20 \\\n",
        "    --sampling_strategy='n_samples_sequential'\\\n",
        "    --dataset='master-data'\\\n",
        "    --num_train_epochs=5 \\\n",
        "    --random_sampling_indexes_file='/content/AA-GAN-Bert/data/experiment_2/random_sampling_100_split_index.csv'\\\n",
        "    --case_id=4 \\\n",
        "    --random_sample_size=100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "mRrFkKeJPBsF"
      },
      "outputs": [],
      "source": [
        "!PYTHONPATH=./:$PYTHONPATH python run_modal.py \\\n",
        "    --wandb_project_name='experiment_3_random_sampling_case_6'\\\n",
        "    --training_strategy='random_sampling_wandb'\\\n",
        "    --model_name='artifacts/gan_bert_model:v0' \\\n",
        "    --sample_size=20 \\\n",
        "    --sampling_strategy='n_samples_sequential'\\\n",
        "    --dataset='master-data'\\\n",
        "    --num_train_epochs=5 \\\n",
        "    --random_sampling_indexes_file='/content/AA-GAN-Bert/data/experiment_2/random_sampling_100_split_index.csv'\\\n",
        "    --case_id=6 \\\n",
        "    --random_sample_size=100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lWgQwYJ7PCVL"
      },
      "outputs": [],
      "source": [
        "!PYTHONPATH=./:$PYTHONPATH python run_modal.py \\\n",
        "    --wandb_project_name='experiment_3_random_sampling_case_8'\\\n",
        "    --training_strategy='random_sampling_wandb'\\\n",
        "    --model_name='artifacts/gan_bert_model:v0' \\\n",
        "    --sample_size=20 \\\n",
        "    --sampling_strategy='n_samples_sequential'\\\n",
        "    --dataset='master-data'\\\n",
        "    --num_train_epochs=5 \\\n",
        "    --random_sampling_indexes_file='/content/AA-GAN-Bert/data/experiment_2/random_sampling_100_split_index.csv'\\\n",
        "    --case_id=8 \\\n",
        "    --random_sample_size=100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "6eAQ3zEHPIr7"
      },
      "outputs": [],
      "source": [
        "!PYTHONPATH=./:$PYTHONPATH python run_modal.py \\\n",
        "    --wandb_project_name='experiment_3_random_sampling_case_10'\\\n",
        "    --training_strategy='random_sampling_wandb'\\\n",
        "    --model_name='artifacts/gan_bert_model:v0' \\\n",
        "    --sample_size=20 \\\n",
        "    --sampling_strategy='n_samples_sequential'\\\n",
        "    --dataset='master-data'\\\n",
        "    --num_train_epochs=5 \\\n",
        "    --random_sampling_indexes_file='/content/AA-GAN-Bert/data/experiment_2/random_sampling_100_split_index.csv'\\\n",
        "    --case_id=10 \\\n",
        "    --random_sample_size=100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QBAkW3l_PK4N"
      },
      "outputs": [],
      "source": [
        "!PYTHONPATH=./:$PYTHONPATH python run_modal.py \\\n",
        "    --wandb_project_name='experiment_3_random_sampling_case_12'\\\n",
        "    --training_strategy='random_sampling_wandb'\\\n",
        "    --model_name='artifacts/gan_bert_model:v0' \\\n",
        "    --sample_size=20 \\\n",
        "    --sampling_strategy='n_samples_sequential'\\\n",
        "    --dataset='master-data'\\\n",
        "    --num_train_epochs=5 \\\n",
        "    --random_sampling_indexes_file='/content/AA-GAN-Bert/data/experiment_2/random_sampling_100_split_index.csv'\\\n",
        "    --case_id=12 \\\n",
        "    --random_sample_size=100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "PAFHLPJVPM1s"
      },
      "outputs": [],
      "source": [
        "!PYTHONPATH=./:$PYTHONPATH python run_modal.py \\\n",
        "    --wandb_project_name='experiment_3_random_sampling_case_14'\\\n",
        "    --training_strategy='random_sampling_wandb'\\\n",
        "    --model_name='artifacts/gan_bert_model:v0' \\\n",
        "    --sample_size=20 \\\n",
        "    --sampling_strategy='n_samples_sequential'\\\n",
        "    --dataset='master-data'\\\n",
        "    --num_train_epochs=5 \\\n",
        "    --random_sampling_indexes_file='/content/AA-GAN-Bert/data/experiment_2/random_sampling_100_split_index.csv'\\\n",
        "    --case_id=14 \\\n",
        "    --random_sample_size=100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tNnHTTmSPO--"
      },
      "outputs": [],
      "source": [
        "!PYTHONPATH=./:$PYTHONPATH python run_modal.py \\\n",
        "    --wandb_project_name='experiment_3_random_sampling_case_16'\\\n",
        "    --training_strategy='random_sampling_wandb'\\\n",
        "    --model_name='artifacts/gan_bert_model:v0' \\\n",
        "    --sample_size=20 \\\n",
        "    --sampling_strategy='n_samples_sequential'\\\n",
        "    --dataset='master-data'\\\n",
        "    --num_train_epochs=5 \\\n",
        "    --random_sampling_indexes_file='/content/AA-GAN-Bert/data/experiment_2/random_sampling_100_split_index.csv'\\\n",
        "    --case_id=16 \\\n",
        "    --random_sample_size=100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tnrf_DKzwi8s",
        "outputId": "724fb10b-bfa8-4a78-bb38-d3805581ac97"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/AA-GAN-Bert\n"
          ]
        }
      ],
      "source": [
        "cd AA-GAN-Bert/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uRTzoxDlPRgD"
      },
      "outputs": [],
      "source": [
        "!PYTHONPATH=./:$PYTHONPATH python run_modal.py \\\n",
        "    --wandb_project_name='experiment_3_random_sampling_case_18'\\\n",
        "    --training_strategy='random_sampling_wandb'\\\n",
        "    --model_name='artifacts/gan_bert_model:v0' \\\n",
        "    --sample_size=20 \\\n",
        "    --sampling_strategy='n_samples_sequential'\\\n",
        "    --dataset='master-data'\\\n",
        "    --num_train_epochs=5 \\\n",
        "    --random_sampling_indexes_file='/content/AA-GAN-Bert/data/experiment_2/random_sampling_100_split_index.csv'\\\n",
        "    --case_id=18 \\\n",
        "    --random_sample_size=100"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Baseline Datasets"
      ],
      "metadata": {
        "id": "YBBA5qvYvvJA"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ut1ROdD6wZKY"
      },
      "source": [
        "## Generate datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# General\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import itertools\n",
        "from pandas import DataFrame\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.font_manager as fm\n",
        "from matplotlib.collections import QuadMesh\n",
        "import seaborn as sn\n",
        "import plotly.express as px\n",
        "\n",
        "# Feature extraction approach\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from string import punctuation\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Classification\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgbm\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# BERT classifier\n",
        "# Installing a custom version of Simple Transformers\n",
        "!git clone https://github.com/NVIDIA/apex\n",
        "!pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./apex\n",
        "#!git init\n",
        "!pip install --upgrade tqdm\n",
        "#!git remote add origin https://github.com/ThilinaRajapakse/simpletransformers.git\n",
        "#!git pull origin master\n",
        "##!pip install -r requirements-dev.txt\n",
        "!pip install transformers\n",
        "!pip install tensorboardX\n",
        "\n",
        "!pip install simpletransformers\n",
        "from simpletransformers.classification import ClassificationModel\n",
        "\n",
        "import torch\n",
        "\n",
        "# Access to the file\n",
        "!pip install PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Parallelize apply on Pandas\n",
        "!pip install pandarallel\n",
        "from pandarallel import pandarallel\n",
        "pandarallel.initialize()\n",
        "\n",
        "# Evaluation\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "woJ5YPRR7qdE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4S0dtl6bwZKf"
      },
      "source": [
        "### IMDB 20 authors"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def run_iterations(source=\"enron\", recompute = False):\n",
        "\n",
        "  # Load data and remove emails containing the sender's name\n",
        "\n",
        "  print(\"Loading and processing dataframe\")\n",
        "\n",
        "  ## Pre-processing functions\n",
        "  def is_name_in_email(name, email):\n",
        "    \"\"\"\n",
        "    Removing emails from Enron where name is in email\n",
        "    \"\"\"\n",
        "\n",
        "    if str(name).lower() in str(email).lower():\n",
        "      return 1\n",
        "    else:\n",
        "      return 0\n",
        "\n",
        "  def fil_sent(sent):\n",
        "      \"\"\"\n",
        "      Filter stopwords\n",
        "      \"\"\"\n",
        "\n",
        "      filtered_sentence = ' '.join([w for w in sent.split() if not w in stop_words])\n",
        "      return filtered_sentence\n",
        "\n",
        "  def process(sent):\n",
        "      \"\"\"\n",
        "      Apply stemming\n",
        "      \"\"\"\n",
        "\n",
        "      sent = str(sent)\n",
        "      return fil_sent(' '.join([ps.stem(str(x).lower()) for x in word_tokenize(sent)]))\n",
        "\n",
        "  stop_words = set(stopwords.words('english'))\n",
        "  ps = PorterStemmer()\n",
        "\n",
        "  def extract_style(text):\n",
        "    \"\"\"\n",
        "    Extracting stylometric features of a text\n",
        "    \"\"\"\n",
        "\n",
        "    text = str(text)\n",
        "    len_text = len(text)\n",
        "    len_words = len(text.split())\n",
        "    avg_len = np.mean([len(t) for t in text.split()])\n",
        "    num_short_w = len([t for t in text.split() if len(t) < 3])\n",
        "    per_digit = sum(t.isdigit() for t in text)/len(text)\n",
        "    per_cap = sum(1 for t in text if t.isupper())/len(text)\n",
        "    f_a = sum(1 for t in text if t.lower() == \"a\")/len(text)\n",
        "    f_b = sum(1 for t in text if t.lower() == \"b\")/len(text)\n",
        "    f_c = sum(1 for t in text if t.lower() == \"c\")/len(text)\n",
        "    f_d = sum(1 for t in text if t.lower() == \"d\")/len(text)\n",
        "    f_e = sum(1 for t in text if t.lower() == \"e\")/len(text)\n",
        "    f_f = sum(1 for t in text if t.lower() == \"f\")/len(text)\n",
        "    f_g = sum(1 for t in text if t.lower() == \"g\")/len(text)\n",
        "    f_h = sum(1 for t in text if t.lower() == \"h\")/len(text)\n",
        "    f_i = sum(1 for t in text if t.lower() == \"i\")/len(text)\n",
        "    f_j = sum(1 for t in text if t.lower() == \"j\")/len(text)\n",
        "    f_k = sum(1 for t in text if t.lower() == \"k\")/len(text)\n",
        "    f_l = sum(1 for t in text if t.lower() == \"l\")/len(text)\n",
        "    f_m = sum(1 for t in text if t.lower() == \"m\")/len(text)\n",
        "    f_n = sum(1 for t in text if t.lower() == \"n\")/len(text)\n",
        "    f_o = sum(1 for t in text if t.lower() == \"o\")/len(text)\n",
        "    f_p = sum(1 for t in text if t.lower() == \"p\")/len(text)\n",
        "    f_q = sum(1 for t in text if t.lower() == \"q\")/len(text)\n",
        "    f_r = sum(1 for t in text if t.lower() == \"r\")/len(text)\n",
        "    f_s = sum(1 for t in text if t.lower() == \"s\")/len(text)\n",
        "    f_t = sum(1 for t in text if t.lower() == \"t\")/len(text)\n",
        "    f_u = sum(1 for t in text if t.lower() == \"u\")/len(text)\n",
        "    f_v = sum(1 for t in text if t.lower() == \"v\")/len(text)\n",
        "    f_w = sum(1 for t in text if t.lower() == \"w\")/len(text)\n",
        "    f_x = sum(1 for t in text if t.lower() == \"x\")/len(text)\n",
        "    f_y = sum(1 for t in text if t.lower() == \"y\")/len(text)\n",
        "    f_z = sum(1 for t in text if t.lower() == \"z\")/len(text)\n",
        "    f_1 = sum(1 for t in text if t.lower() == \"1\")/len(text)\n",
        "    f_2 = sum(1 for t in text if t.lower() == \"2\")/len(text)\n",
        "    f_3 = sum(1 for t in text if t.lower() == \"3\")/len(text)\n",
        "    f_4 = sum(1 for t in text if t.lower() == \"4\")/len(text)\n",
        "    f_5 = sum(1 for t in text if t.lower() == \"5\")/len(text)\n",
        "    f_6 = sum(1 for t in text if t.lower() == \"6\")/len(text)\n",
        "    f_7 = sum(1 for t in text if t.lower() == \"7\")/len(text)\n",
        "    f_8 = sum(1 for t in text if t.lower() == \"8\")/len(text)\n",
        "    f_9 = sum(1 for t in text if t.lower() == \"9\")/len(text)\n",
        "    f_0 = sum(1 for t in text if t.lower() == \"0\")/len(text)\n",
        "    f_e_0 = sum(1 for t in text if t.lower() == \"!\")/len(text)\n",
        "    f_e_1 = sum(1 for t in text if t.lower() == \"-\")/len(text)\n",
        "    f_e_2 = sum(1 for t in text if t.lower() == \":\")/len(text)\n",
        "    f_e_3 = sum(1 for t in text if t.lower() == \"?\")/len(text)\n",
        "    f_e_4 = sum(1 for t in text if t.lower() == \".\")/len(text)\n",
        "    f_e_5 = sum(1 for t in text if t.lower() == \",\")/len(text)\n",
        "    f_e_6 = sum(1 for t in text if t.lower() == \";\")/len(text)\n",
        "    f_e_7 = sum(1 for t in text if t.lower() == \"'\")/len(text)\n",
        "    f_e_8 = sum(1 for t in text if t.lower() == \"/\")/len(text)\n",
        "    f_e_9 = sum(1 for t in text if t.lower() == \"(\")/len(text)\n",
        "    f_e_10 = sum(1 for t in text if t.lower() == \")\")/len(text)\n",
        "    f_e_11 = sum(1 for t in text if t.lower() == \"&\")/len(text)\n",
        "    richness = len(list(set(text.split())))/len(text.split())\n",
        "\n",
        "    return pd.Series([avg_len, len_text, len_words, num_short_w, per_digit, per_cap, f_a, f_b, f_c, f_d, f_e, f_f, f_g, f_h, f_i, f_j, f_k, f_l, f_m, f_n, f_o, f_p, f_q, f_r, f_s, f_t, f_u, f_v, f_w, f_x, f_y, f_z, f_0, f_1, f_2, f_3, f_4, f_5, f_6, f_7, f_8, f_9, f_e_0, f_e_1, f_e_2, f_e_3, f_e_4, f_e_5, f_e_6, f_e_7, f_e_8, f_e_9, f_e_10, f_e_11, richness])\n",
        "\n",
        "  list_senders = [5, 10, 25, 50, 75, 100]\n",
        "\n",
        "  df = pd.read_csv(\"/content/imdb62.txt\", sep=\"\\t\", header = None)\n",
        "  df.columns = [\"reviewid\", \"From\", \"Itemid\", \"grade\", \"title\", \"content\"]\n",
        "  # df = df[:5000]\n",
        "  # print(df.head())\n",
        "  df['content_tfidf'] = df['content'].parallel_apply(lambda x: process(x))\n",
        "  df[[\"avg_len\", \"len_text\", \"len_words\", \"num_short_w\", \"per_digit\", \"per_cap\", \"f_a\", \"f_b\", \"f_c\", \"f_d\", \"f_e\", \"f_f\", \"f_g\", \"f_h\", \"f_i\", \"f_j\", \"f_k\", \"f_l\", \"f_m\", \"f_n\", \"f_o\", \"f_p\", \"f_q\", \"f_r\", \"f_s\", \"f_t\", \"f_u\", \"f_v\", \"f_w\", \"f_x\", \"f_y\", \"f_z\", \"f_0\", \"f_1\", \"f_2\", \"f_3\", \"f_4\", \"f_5\", \"f_6\", \"f_7\", \"f_8\", \"f_9\",  \"f_e_0\", \"f_e_1\", \"f_e_2\", \"f_e_3\", \"f_e_4\", \"f_e_5\", \"f_e_6\", \"f_e_7\", \"f_e_8\", \"f_e_9\", \"f_e_10\", \"f_e_11\", \"richness\"]] = df['content'].parallel_apply(lambda x: extract_style(x))\n",
        "  df.to_csv(\"/content/Baselines/full_imdb62.csv\")\n",
        "\n"
      ],
      "metadata": {
        "id": "43359a1Ww814"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_iterations()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBYhqgUq7LPh",
        "outputId": "0b2c144b-6537-41b4-8133-dad4430646bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading and processing dataframe\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/Baselines/full_imdb62.csv\", index_col = 0)"
      ],
      "metadata": {
        "id": "mXw2-o3d9uei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DGREjzZKqpHD",
        "outputId": "a0e8b1a0-f63a-466d-cbd7-505da32a3c64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "61987"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.rename(columns={'content': 'BookText', 'From': 'AuthorID'})\n",
        "df.to_csv(\"/content/Baselines/full_imdb62_ganbert.csv\")"
      ],
      "metadata": {
        "id": "AdtRaOUu9yRx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/Baselines/apex"
      ],
      "metadata": {
        "id": "dydq3Tm_8wvx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Blog dataset"
      ],
      "metadata": {
        "id": "1Rm7ti07KKIe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_iterations(source=\"enron\", recompute = False):\n",
        "\n",
        "  # Load data and remove emails containing the sender's name\n",
        "\n",
        "  print(\"Loading and processing dataframe\")\n",
        "\n",
        "  ## Pre-processing functions\n",
        "  def is_name_in_email(name, email):\n",
        "    \"\"\"\n",
        "    Removing emails from Enron where name is in email\n",
        "    \"\"\"\n",
        "\n",
        "    if str(name).lower() in str(email).lower():\n",
        "      return 1\n",
        "    else:\n",
        "      return 0\n",
        "\n",
        "  def fil_sent(sent):\n",
        "      \"\"\"\n",
        "      Filter stopwords\n",
        "      \"\"\"\n",
        "\n",
        "      filtered_sentence = ' '.join([w for w in sent.split() if not w in stop_words])\n",
        "      return filtered_sentence\n",
        "\n",
        "  def process(sent):\n",
        "      \"\"\"\n",
        "      Apply stemming\n",
        "      \"\"\"\n",
        "\n",
        "      sent = str(sent)\n",
        "      return fil_sent(' '.join([ps.stem(str(x).lower()) for x in word_tokenize(sent)]))\n",
        "\n",
        "  stop_words = set(stopwords.words('english'))\n",
        "  ps = PorterStemmer()\n",
        "\n",
        "  def extract_style(text):\n",
        "    \"\"\"\n",
        "    Extracting stylometric features of a text\n",
        "    \"\"\"\n",
        "\n",
        "    text = str(text)\n",
        "    len_text = len(text)\n",
        "    len_words = len(text.split())\n",
        "    avg_len = np.mean([len(t) for t in text.split()])\n",
        "    num_short_w = len([t for t in text.split() if len(t) < 3])\n",
        "    per_digit = sum(t.isdigit() for t in text)/len(text)\n",
        "    per_cap = sum(1 for t in text if t.isupper())/len(text)\n",
        "    f_a = sum(1 for t in text if t.lower() == \"a\")/len(text)\n",
        "    f_b = sum(1 for t in text if t.lower() == \"b\")/len(text)\n",
        "    f_c = sum(1 for t in text if t.lower() == \"c\")/len(text)\n",
        "    f_d = sum(1 for t in text if t.lower() == \"d\")/len(text)\n",
        "    f_e = sum(1 for t in text if t.lower() == \"e\")/len(text)\n",
        "    f_f = sum(1 for t in text if t.lower() == \"f\")/len(text)\n",
        "    f_g = sum(1 for t in text if t.lower() == \"g\")/len(text)\n",
        "    f_h = sum(1 for t in text if t.lower() == \"h\")/len(text)\n",
        "    f_i = sum(1 for t in text if t.lower() == \"i\")/len(text)\n",
        "    f_j = sum(1 for t in text if t.lower() == \"j\")/len(text)\n",
        "    f_k = sum(1 for t in text if t.lower() == \"k\")/len(text)\n",
        "    f_l = sum(1 for t in text if t.lower() == \"l\")/len(text)\n",
        "    f_m = sum(1 for t in text if t.lower() == \"m\")/len(text)\n",
        "    f_n = sum(1 for t in text if t.lower() == \"n\")/len(text)\n",
        "    f_o = sum(1 for t in text if t.lower() == \"o\")/len(text)\n",
        "    f_p = sum(1 for t in text if t.lower() == \"p\")/len(text)\n",
        "    f_q = sum(1 for t in text if t.lower() == \"q\")/len(text)\n",
        "    f_r = sum(1 for t in text if t.lower() == \"r\")/len(text)\n",
        "    f_s = sum(1 for t in text if t.lower() == \"s\")/len(text)\n",
        "    f_t = sum(1 for t in text if t.lower() == \"t\")/len(text)\n",
        "    f_u = sum(1 for t in text if t.lower() == \"u\")/len(text)\n",
        "    f_v = sum(1 for t in text if t.lower() == \"v\")/len(text)\n",
        "    f_w = sum(1 for t in text if t.lower() == \"w\")/len(text)\n",
        "    f_x = sum(1 for t in text if t.lower() == \"x\")/len(text)\n",
        "    f_y = sum(1 for t in text if t.lower() == \"y\")/len(text)\n",
        "    f_z = sum(1 for t in text if t.lower() == \"z\")/len(text)\n",
        "    f_1 = sum(1 for t in text if t.lower() == \"1\")/len(text)\n",
        "    f_2 = sum(1 for t in text if t.lower() == \"2\")/len(text)\n",
        "    f_3 = sum(1 for t in text if t.lower() == \"3\")/len(text)\n",
        "    f_4 = sum(1 for t in text if t.lower() == \"4\")/len(text)\n",
        "    f_5 = sum(1 for t in text if t.lower() == \"5\")/len(text)\n",
        "    f_6 = sum(1 for t in text if t.lower() == \"6\")/len(text)\n",
        "    f_7 = sum(1 for t in text if t.lower() == \"7\")/len(text)\n",
        "    f_8 = sum(1 for t in text if t.lower() == \"8\")/len(text)\n",
        "    f_9 = sum(1 for t in text if t.lower() == \"9\")/len(text)\n",
        "    f_0 = sum(1 for t in text if t.lower() == \"0\")/len(text)\n",
        "    f_e_0 = sum(1 for t in text if t.lower() == \"!\")/len(text)\n",
        "    f_e_1 = sum(1 for t in text if t.lower() == \"-\")/len(text)\n",
        "    f_e_2 = sum(1 for t in text if t.lower() == \":\")/len(text)\n",
        "    f_e_3 = sum(1 for t in text if t.lower() == \"?\")/len(text)\n",
        "    f_e_4 = sum(1 for t in text if t.lower() == \".\")/len(text)\n",
        "    f_e_5 = sum(1 for t in text if t.lower() == \",\")/len(text)\n",
        "    f_e_6 = sum(1 for t in text if t.lower() == \";\")/len(text)\n",
        "    f_e_7 = sum(1 for t in text if t.lower() == \"'\")/len(text)\n",
        "    f_e_8 = sum(1 for t in text if t.lower() == \"/\")/len(text)\n",
        "    f_e_9 = sum(1 for t in text if t.lower() == \"(\")/len(text)\n",
        "    f_e_10 = sum(1 for t in text if t.lower() == \")\")/len(text)\n",
        "    f_e_11 = sum(1 for t in text if t.lower() == \"&\")/len(text)\n",
        "    richness = len(list(set(text.split())))/len(text.split())\n",
        "\n",
        "    return pd.Series([avg_len, len_text, len_words, num_short_w, per_digit, per_cap, f_a, f_b, f_c, f_d, f_e, f_f, f_g, f_h, f_i, f_j, f_k, f_l, f_m, f_n, f_o, f_p, f_q, f_r, f_s, f_t, f_u, f_v, f_w, f_x, f_y, f_z, f_0, f_1, f_2, f_3, f_4, f_5, f_6, f_7, f_8, f_9, f_e_0, f_e_1, f_e_2, f_e_3, f_e_4, f_e_5, f_e_6, f_e_7, f_e_8, f_e_9, f_e_10, f_e_11, richness])\n",
        "\n",
        "  list_senders = [5, 10, 25, 50, 75, 100]\n",
        "\n",
        "\n",
        "  df = pd.read_csv('/content/blogtext.csv')\n",
        "  # df = df[:10]\n",
        "  df.columns = [\"From\", \"Gender\", \"Age\", \"Topic\", \"Sign\", \"Date\", \"content\"]\n",
        "  df = df[df['content'].apply(lambda x: len(x.split())) > 0]\n",
        "  df['content_tfidf'] = df['content'].parallel_apply(lambda x: process(x))\n",
        "  df[[\"avg_len\", \"len_text\", \"len_words\", \"num_short_w\", \"per_digit\", \"per_cap\", \"f_a\", \"f_b\", \"f_c\", \"f_d\", \"f_e\", \"f_f\", \"f_g\", \"f_h\", \"f_i\", \"f_j\", \"f_k\", \"f_l\", \"f_m\", \"f_n\", \"f_o\", \"f_p\", \"f_q\", \"f_r\", \"f_s\", \"f_t\", \"f_u\", \"f_v\", \"f_w\", \"f_x\", \"f_y\", \"f_z\", \"f_0\", \"f_1\", \"f_2\", \"f_3\", \"f_4\", \"f_5\", \"f_6\", \"f_7\", \"f_8\", \"f_9\",  \"f_e_0\", \"f_e_1\", \"f_e_2\", \"f_e_3\", \"f_e_4\", \"f_e_5\", \"f_e_6\", \"f_e_7\", \"f_e_8\", \"f_e_9\", \"f_e_10\", \"f_e_11\", \"richness\"]] = df['content'].parallel_apply(lambda x: extract_style(x))\n",
        "  df.to_csv(\"/content/Baselines/full_blog.csv\")"
      ],
      "metadata": {
        "id": "Loxd7_sxKOKV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_iterations()"
      ],
      "metadata": {
        "id": "_JMVjSpYKOKW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "195a9239-65c6-4d9b-a83b-d21f5520fc4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading and processing dataframe\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/Baselines/full_blog.csv\", index_col = 0)"
      ],
      "metadata": {
        "id": "PTYOLrzZKOKW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.rename(columns={'content': 'BookText', 'From': 'AuthorID'})\n",
        "df.to_csv(\"/content/Baselines/full_blog_ganbert.csv\")"
      ],
      "metadata": {
        "id": "8p2upx6PKOKX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GAN-BERT Experiments"
      ],
      "metadata": {
        "id": "jpdhSTr79e0Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/AA-GAN-Bert"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6CrSdUCBnuk",
        "outputId": "8db2fd7b-f13d-4a9d-a8eb-a335f58597c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/AA-GAN-Bert\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### IMDB-full"
      ],
      "metadata": {
        "id": "RF1VCQfeU0bM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!PYTHONPATH=./:$PYTHONPATH python run_modal.py \\\n",
        "    --wandb_project_name='baselines'\\\n",
        "    --training_strategy='best_modal_on_wandb'\\\n",
        "    --sample_size=20 \\\n",
        "    --sampling_strategy='n_samples_sequential'\\\n",
        "    --dataset='Baselines'\\\n",
        "    --dataset_dir='full_imdb62_ganbert.csv'\\\n",
        "    --num_train_epochs=10"
      ],
      "metadata": {
        "id": "c9WPpBg99d1p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### IMDB-20"
      ],
      "metadata": {
        "id": "WPYvSo2bhaX-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!PYTHONPATH=./:$PYTHONPATH python run_modal.py \\\n",
        "    --wandb_project_name='baselines'\\\n",
        "    --training_strategy='best_modal_on_wandb'\\\n",
        "    --sample_size=20 \\\n",
        "    --sampling_strategy='n_samples_sequential'\\\n",
        "    --dataset='Baselines'\\\n",
        "    --dataset_dir='imdb20_ganbert.csv'\\\n",
        "    --num_train_epochs=10"
      ],
      "metadata": {
        "id": "W3yuMfwRhaX_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/Baselines"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AgjgM1GQhaYA",
        "outputId": "39b0dd09-5d13-4c15-bf45-0ab997319f1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Baselines\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git pull"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0YXK6YqFlaVF",
        "outputId": "27b7df60-0b63-4798-935c-52a962688b7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "remote: Enumerating objects: 10, done.\u001b[K\n",
            "remote: Counting objects:  10% (1/10)\u001b[K\rremote: Counting objects:  20% (2/10)\u001b[K\rremote: Counting objects:  30% (3/10)\u001b[K\rremote: Counting objects:  40% (4/10)\u001b[K\rremote: Counting objects:  50% (5/10)\u001b[K\rremote: Counting objects:  60% (6/10)\u001b[K\rremote: Counting objects:  70% (7/10)\u001b[K\rremote: Counting objects:  80% (8/10)\u001b[K\rremote: Counting objects:  90% (9/10)\u001b[K\rremote: Counting objects: 100% (10/10)\u001b[K\rremote: Counting objects: 100% (10/10), done.\u001b[K\n",
            "remote: Compressing objects:  12% (1/8)\u001b[K\rremote: Compressing objects:  25% (2/8)\u001b[K\rremote: Compressing objects:  37% (3/8)\u001b[K\rremote: Compressing objects:  50% (4/8)\u001b[K\rremote: Compressing objects:  62% (5/8)\u001b[K\rremote: Compressing objects:  75% (6/8)\u001b[K\rremote: Compressing objects:  87% (7/8)\u001b[K\rremote: Compressing objects: 100% (8/8)\u001b[K\rremote: Compressing objects: 100% (8/8), done.\u001b[K\n",
            "remote: Total 8 (delta 4), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects:  12% (1/8)\rUnpacking objects:  25% (2/8)\rUnpacking objects:  37% (3/8)\rUnpacking objects:  50% (4/8)\rUnpacking objects:  62% (5/8)\rUnpacking objects:  75% (6/8)\rUnpacking objects:  87% (7/8)\rUnpacking objects: 100% (8/8)\rUnpacking objects: 100% (8/8), 830 bytes | 830.00 KiB/s, done.\n",
            "From https://huggingface.co/datasets/Authorship/Baselines\n",
            "   7a23f48..6986157  main       -> origin/main\n",
            "Updating 7a23f48..6986157\n",
            "Filtering content: 100% (2/2), 34.03 MiB | 4.99 MiB/s, done.\n",
            "Fast-forward\n",
            " .gitattributes     | 2 \u001b[32m++\u001b[m\n",
            " imdb20_ganbert.csv | 3 \u001b[32m+++\u001b[m\n",
            " imdb_20.csv        | 3 \u001b[32m+++\u001b[m\n",
            " 3 files changed, 8 insertions(+)\n",
            " create mode 100644 imdb20_ganbert.csv\n",
            " create mode 100644 imdb_20.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/Baselines/imdb20_ganbert.csv')"
      ],
      "metadata": {
        "id": "8epsglb2YEO5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(df)"
      ],
      "metadata": {
        "id": "bxTw81zglgBJ",
        "outputId": "4241f85f-e462-4573-a6a5-039298bf790d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5000"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Blog-full"
      ],
      "metadata": {
        "id": "xDWuc4znYEtX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!PYTHONPATH=./:$PYTHONPATH python run_modal.py \\\n",
        "    --wandb_project_name='baselines'\\\n",
        "    --training_strategy='best_modal_on_wandb'\\\n",
        "    --sample_size=20 \\\n",
        "    --sampling_strategy='n_samples_sequential'\\\n",
        "    --dataset='Baselines'\\\n",
        "    --dataset_dir='full_blog_ganbert.csv'\\\n",
        "    --num_train_epochs=10"
      ],
      "metadata": {
        "id": "164YdnvPYEtY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Blog-20"
      ],
      "metadata": {
        "id": "scajGvN7s3Ec"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!PYTHONPATH=./:$PYTHONPATH python run_modal.py \\\n",
        "    --wandb_project_name='baselines'\\\n",
        "    --training_strategy='best_modal_on_wandb'\\\n",
        "    --sample_size=20 \\\n",
        "    --sampling_strategy='n_samples_sequential'\\\n",
        "    --dataset='Baselines'\\\n",
        "    --dataset_dir='blog20_ganbert.csv'\\\n",
        "    --num_train_epochs=10"
      ],
      "metadata": {
        "id": "51tww1Lzs3Ed"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "Gi5k1kpWzb1b",
        "D2773oIWU7Yv",
        "GsREcMszOrE8",
        "cpjFMD0JN79E",
        "7mzmyC4q53kA",
        "JUbYuIH4Ps7Y",
        "m-FT9vF5P1EE",
        "WyX4ZavGQU4h",
        "dNp3cDHFQiGb",
        "UeMvZOSLQvV-",
        "AXGoSub3Q603",
        "lVgE5Ya4RHhW",
        "GSk8nhQd5j-b",
        "NF10rEBLKGbY"
      ],
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "gpuClass": "premium",
      "include_colab_link": true
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}